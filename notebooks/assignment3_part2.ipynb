{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262ee4f1cc793d5cc0302d24cbc64461",
     "grade": false,
     "grade_id": "cell-aa820d6aaf4304db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2e231be8687eedeee723835e4f8ea8f",
     "grade": false,
     "grade_id": "cell-24e63ee011a83003",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 3 Part 2: Multiple Time Series Forecasting (50 pts)\n",
    "\n",
    "In this assignment, we're going to study forecasting and causality testing that involve multiple time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d940d1b99e988cc02a4365af87abae75",
     "grade": false,
     "grade_id": "cell-0153dc3ed86e1f61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "warnings.simplefilter(\"ignore\", ValueWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e28994617f152a215ff09ca84262214",
     "grade": false,
     "grade_id": "cell-971449a9e8d421fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will explore the same five time series about **daily new COVID-19 cases for the top 5 countries with the most cumulative cases as of August 21, 2020** as we had in **Assignment 2 Part 2**. In order not to reinvent the suspension either, let's import the other `load_data` function you wrote previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24f5ad2e27800bc9795ffd3b2bc5ec3a",
     "grade": false,
     "grade_id": "cell-0905690ea7fef10f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Copy and paste the function you wrote in Assignment 2 Part 2 here and import any libraries necessary\n",
    "# We have tried a more elegant solution by using\n",
    "# from ipynb.fs.defs.assignment2_part2 import load_data\n",
    "# but it doesn't work with the autograder...\n",
    "\n",
    "def load_data():\n",
    "    daily_new_cases = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return daily_new_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99714c8f08e9f580313b5e2d0067b206",
     "grade": true,
     "grade_id": "cell-da753c6330d318a8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks to make sure you have imported the correct function - no points awarded\n",
    "\n",
    "stu_ans = load_data()\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q0: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (212, 5), \"Q0: The shape of your pd.DataFrame returned is incorrect. \"\n",
    "assert isinstance(stu_ans.index, pd.DatetimeIndex), \"Q0: The index of your pd.DataFrame must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-01-23\" <= stu_ans.index) & (stu_ans.index <= \"2020-08-21\")).all(), \"Q0: The index of your pd.DataFrame contains an incorrect time range. \"\n",
    "assert not stu_ans.isna().any(axis=None), \"Q0: Your pd.DataFrame contains NaN values. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q0: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dcef4ecddc111dac9bcf9f21ef841c9",
     "grade": false,
     "grade_id": "cell-d63bebc6fef0f0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Vector Autoregression (VAR) (35 pts)\n",
    "\n",
    "There may be interesting relationships that exist among multiple time series. One way of uncovering such relationships is to perform a VAR, where we model a time series not only with its own observations but also observations from other possibly related time series. In this question, we'll explore how to apply VAR to the five time series about daily new COVID-19 cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7c7f07903b8df87736655305bd5683",
     "grade": false,
     "grade_id": "cell-902e515e7633ecbd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1a (25 pts)\n",
    "\n",
    "Complete the function below that fits a $\\mathrm{VAR}(p)$ model on the **first-order differences** of multiple input time series given as a `pd.DataFrame` and that makes forecasts in the original data space (i.e., the number of daily new cases). The function should return the trained VAR model as either a `VARResults` or `VARResultsWrapper` object, and its forecasts as a `pd.DataFrame`. \n",
    "\n",
    "For example, when parameter `num_forecasts=20`, the forecasts should be a `pd.DataFrame` like the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**2020-08-22**|34966.352289|27554.442883|66616.742795|4880.479802|1304.572448|\n",
    "|**2020-08-23**|29196.140510|18778.000769|64704.583332|4644.870185|963.191434|\n",
    "|**2020-08-24**|29317.565141|27333.717530|67000.950077|4454.998897|-305.011015|\n",
    "|**...**|...|...|...|...|...|\n",
    "|**2020-09-08**|30778.194852|54899.944448|77734.373256|4293.506363|-1871.868813|\n",
    "|**2020-09-09**|32638.701231|55789.197274|80176.803330|4476.211786|-299.954762|\n",
    "|**2020-09-10**|29185.068081|41457.646648|79565.796202|4678.429342|-348.964443|\n",
    "\n",
    "\n",
    "where\n",
    "* the index of the DataFrame is a `pd.DatetimeIndex`; \n",
    "* the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from left to right;\n",
    "* the values of the DataFrame are the forecasts; and\n",
    "* the DataFrame doesn't contain any `NaN` values. \n",
    "\n",
    "**This function should return a `tuple` of length 2, whose first element is either a `VARResults` or `VARResultsWrapper` object representing a trained VAR model and whose last element is a `pd.DataFrame` of shape `(num_forecasts, 5)` representing the forecasts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d1b8d66402ce4ad174655c76cea017",
     "grade": false,
     "grade_id": "cell-b77dce5d7fb758f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.var_model import VARResults, VARResultsWrapper\n",
    "\n",
    "def var_first_diff(df, p, num_forecasts):\n",
    "    \"\"\"\n",
    "    Fits a VAR(p) model on the first-order diff on a df and makes num_forecasts forecasts\n",
    "    \"\"\"\n",
    "    var_res, forecasts = None, None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return var_res, forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0f58368036cf3dbeb247cf4a6bfe1cd",
     "grade": true,
     "grade_id": "cell-9a51c693b6b7588e",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "p, num_forecasts = 7, 20\n",
    "stu_ans = var_first_diff(stu_df, p, num_forecasts)\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q1a: Your function should return a tuple. \"\n",
    "assert len(stu_ans) == 2, \"Q1a: The length of the tuple returned is incorrect. \"\n",
    "\n",
    "# Check the trained VAR model\n",
    "assert isinstance(stu_ans[0], (VARResults, VARResultsWrapper)), \"Q1a: Your trained VAR model should be a VARResults or VARResultsWrapper. \"\n",
    "assert stu_ans[0].nobs == stu_df.shape[0] - 1 - p, \"Q1a: The VAR model was fit with data of an incorrect length. \"\n",
    "assert stu_ans[0].neqs == stu_df.shape[1], \"Q1a: The VAR model was fit with an incorrect number of time series. \"\n",
    "assert stu_ans[0].k_ar == p, \"Q1a: The VAR model was fit with an incorrect value for parameter p. \"\n",
    "\n",
    "# Check the forecasts\n",
    "assert isinstance(stu_ans[1], pd.DataFrame), \"Q1a: Your forecasts should be a pd.DataFrame. \"\n",
    "assert stu_ans[1].shape == (num_forecasts, stu_df.shape[-1]), \"Q1a: The shape of your forecasts returned is incorrect. \"\n",
    "assert isinstance(stu_ans[1].index, pd.DatetimeIndex), \"Q1a: The index of your forecasts must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-08-22\" <= stu_ans[1].index) & (stu_ans[1].index <= \"2020-09-10\")).all(), \"Q1a: The index of your forecasts contains an incorrect time range. \"\n",
    "assert not stu_ans[1].isna().any(axis=None), \"Q1a: Your forecasts contain NaN values. \"\n",
    "assert stu_ans[1].dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q1a: All columns of your forecasts should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ans, stu_df, p, num_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "772a683557fa5a9e51e457f705d45494",
     "grade": false,
     "grade_id": "cell-ab6d3c0e1ad2fb0c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's plot and see your forecasts. Is your VAR model doing a good job? Why or why not?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, num_forecasts = 7, 20\n",
    "\n",
    "stu_df = load_data()\n",
    "_, forecasts = var_first_diff(stu_df, p, num_forecasts)\n",
    "actual = pd.read_pickle(\"assets/actual_multi.pkl\")\n",
    "rmse = np.sqrt(np.mean((actual - forecasts) ** 2, axis=0)).round(2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 8), sharey=True, gridspec_kw={\"wspace\": 0})\n",
    "\n",
    "stu_df.plot(ax=axes[0])\n",
    "\n",
    "stu_df.iloc[-1:].append(actual).plot(ax=axes[1], legend=False)\n",
    "axes[1].set_prop_cycle(None)\n",
    "\n",
    "stu_df.iloc[-1:].append(forecasts).plot(ax=axes[1], legend=False, style=[\"-.\"] * stu_df.shape[-1], linewidth=4)\n",
    "\n",
    "axes[0].set_title(f\"Daily New COVID-19 Cases until {forecasts.index[0]}\", fontsize=14)\n",
    "axes[1].set_title(r\"Forecasted $-\\cdot-\\cdot-$ and Actual --- Daily New COVID-19 Cases\" + \"\\n\" + f\"RMSE: {rmse.to_dict()}\", fontsize=14)\n",
    "\n",
    "del fig, axes, stu_df, p, num_forecasts, forecasts, actual, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3897800ca5376bf08e86d1721a741f70",
     "grade": false,
     "grade_id": "cell-a92dd3ffd846b7b6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1b (10 pts)\n",
    "\n",
    "Now, let's compare the forecasts made by the $\\mathrm{VAR(p)}$ model you trained above with that made by five independent $\\mathrm{AR(p)}$ models for each time series. This way, we will be able to see the effect of including observations from possibly related time series on modelling each invidual time series more clearly. \n",
    "\n",
    "Complete the function below that uses the `arma_first_diff` function you wrote in **Assignment 3 Part 1** to fit five $\\mathrm{AR}(p)$ models, one time series each, and make forecasts for each of the five time series. Return the forecasts as a `pd.DataFrame`. \n",
    "\n",
    "For example, when parameter `num_forecasts=20`, the forecasts should be a `pd.DataFrame` like the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**2020-08-22**|37606.337737|30054.801607|65293.198373|4799.898341|2613.269306|\n",
    "|**2020-08-23**|34659.880538|21722.458140|60235.575280|4795.226196|2096.298645|\n",
    "|**2020-08-24**|31822.923153|24670.815522|64022.272121|4773.476292|1556.778499|\n",
    "|**...**|...|...|...|...|...|\n",
    "|**2020-09-08**|36489.857891|41764.328105|73674.836876|4767.958973|2249.096891|\n",
    "|**2020-09-09**|38427.089594|44335.452439|74071.644729|4767.761722|2587.726648|\n",
    "|**2020-09-10**|39442.677738|39179.959665|71831.680217|4767.538096|2503.294019|\n",
    "\n",
    "where\n",
    "* the index of the DataFrame is a `pd.DatetimeIndex`; \n",
    "* the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from left to right;\n",
    "* the values of the DataFrame are the forecasts; and\n",
    "* the DataFrame doesn't contain any `NaN` values. \n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(num_forecasts, 5)` representing the forecasts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d63588f17984b72732ff7631ef85fb57",
     "grade": false,
     "grade_id": "cell-561752c236ce2186",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Copy and paste the function you wrote in Assignment 3 Part 1\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def arma_first_diff(ser, p, q, num_forecasts):\n",
    "    \"\"\"\n",
    "    Takes a series and fits an ARMA(p, q) model on first-order diff. \n",
    "    Returns a number of forecasts as specified by num_forecasts. \n",
    "    \"\"\"\n",
    "    \n",
    "    forecasts = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9533db03722f14fa12299c10c28cac18",
     "grade": false,
     "grade_id": "cell-7fc406bb9e5d3492",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ar_first_diff(df, p, num_forecasts):\n",
    "    \"\"\"\n",
    "    Fits an AR(p) model on the first-order diff on each time series in df and makes num_forecasts forecasts\n",
    "    \"\"\"\n",
    "    forecasts = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b8d8c78f19e2e84959d929ec927cefb",
     "grade": true,
     "grade_id": "cell-d88da58ec43236f1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "p, num_forecasts = 7, 20\n",
    "stu_ans = ar_first_diff(stu_df, p, num_forecasts)\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q1b: Your forecasts should be a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (num_forecasts, stu_df.shape[-1]), \"Q1b: The shape of your forecasts returned is incorrect. \"\n",
    "assert isinstance(stu_ans.index, pd.DatetimeIndex), \"Q1b: The index of your forecasts must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-08-22\" <= stu_ans.index) & (stu_ans.index <= \"2020-09-10\")).all(), \"Q1b: The index of your forecasts contains an incorrect time range. \"\n",
    "assert not stu_ans.isna().any(axis=None), \"Q1b: Your forecasts contain NaN values. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q1b: All columns of your forecasts should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ans, stu_df, p, num_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43ba4620d11afd48be9aa1faa4b0b044",
     "grade": false,
     "grade_id": "cell-78c10adfdbe4493c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can of course plot the forecasts made by the five $\\mathrm{AR}(p)$ models. How does the RMSE for each time series compare with that calculated from the forecasts made by a single $\\mathrm{VAR}(p)$ model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, num_forecasts = 7, 20\n",
    "\n",
    "stu_df = load_data()\n",
    "forecasts = ar_first_diff(stu_df, p, num_forecasts)\n",
    "actual = pd.read_pickle(\"assets/actual_multi.pkl\")\n",
    "rmse = np.sqrt(np.mean((actual - forecasts) ** 2, axis=0)).round(2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 8), sharey=True, gridspec_kw={\"wspace\": 0})\n",
    "\n",
    "stu_df.plot(ax=axes[0])\n",
    "\n",
    "stu_df.iloc[-1:].append(actual).plot(ax=axes[1], legend=False)\n",
    "axes[1].set_prop_cycle(None)\n",
    "\n",
    "stu_df.iloc[-1:].append(forecasts).plot(ax=axes[1], legend=False, style=[\"-.\"] * stu_df.shape[-1], linewidth=4)\n",
    "\n",
    "axes[0].set_title(f\"Daily New COVID-19 Cases until {forecasts.index[0]}\", fontsize=14)\n",
    "axes[1].set_title(r\"Forecasted $-\\cdot-\\cdot-$ and Actual --- Daily New COVID-19 Cases\" + \"\\n\" + f\"RMSE: {rmse.to_dict()}\", fontsize=14)\n",
    "\n",
    "del fig, axes, stu_df, p, num_forecasts, forecasts, actual, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d846d52998d6df5c56e8eb1b96453ea",
     "grade": false,
     "grade_id": "cell-2939c5cace465fa0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Granger Causality (15 pts)\n",
    "\n",
    "By comparing the forecasts made by a single $\\mathrm{VAR}(p)$ model and by five independent $\\mathrm{AR}(p)$ models above, you may notice that the RMSE of one country has improved after we \"upgrade\" an $\\mathrm{AR}(p)$ model to include observations from all other time series. It alerts us about the possible *causality* that may exist among these time series, because the inclusion of some other time series enables us to make better forecasts on another one. \n",
    "\n",
    "This is exactly the principle behind Granger Causality test, a statistical test for causality that works by determining whether the inclusion of one time series significantly improves the prediction of the other. Let's now perform a Granger Causality test on each pair of countries and see what we can conclude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "063a29be766186ea496d0b9c774955f5",
     "grade": false,
     "grade_id": "cell-f9dcce57f7fd0e4a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Complete the function below that first fits a $\\mathrm{VAR}(p)$ model on the **first-order differences** of the input `pd.DataFrame` and that then performs a pairwise Granger Causality test **based on F-test** for all possible pairs of the five countries (excluding the pairs formed by a country and itself). The function should return the $p$-value of each pairwise test in a `pd.DataFrame` like the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**?**|NaN|1.234348e-05||||\n",
    "|**?**|6.323140e-01|NaN||||\n",
    "|**?**|||NaN|||\n",
    "|**?**||||NaN||\n",
    "|**?**|||||NaN|\n",
    "\n",
    "where\n",
    "* the index and the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from top to bottom and from left to right; and\n",
    "* **each row represents the *caused* variable and each column represents the *causing* variable**\n",
    "\n",
    "For example, `1.234348e-05` is the $p$-value of the F-test performed to test the null hypothesis that the daily new cases in the Rank 1 country is not *caused by* that in the Rank 2 country. Notice that the \"caused-by\" relation is not symmetric, so the `pd.DataFrame` above is not symmetric either. You may use the `test_causality` function of either `VARResults` or `VARResultsWrapper` class to perform Granger Causality tests. (<b>Hint:</b> different libraries and methods may calculate this value differently and result in problems with the autograder. Please stick to the `test_causality` function built into your `VARResults` or `VARResultsWrapper` class.)\n",
    "\n",
    "The object returned from the `test_causality` function possesses an attribute that gives you the $p$-value of the test as a single number. How do you identify that attribute? (Hint: Python's built-in [`dir`](https://docs.python.org/3/library/functions.html#dir) function can be helpful. )\n",
    "\n",
    "**This function should return a ``pd.DataFrame`` of the shape `(5, 5)`, representing the $p$-value matrix for all pairwise Granger Causality tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4162bb7d955175bdfb413e0e02be0e19",
     "grade": false,
     "grade_id": "cell-e896207bcc59798b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.var_model import VARResults, VARResultsWrapper\n",
    "\n",
    "def test_granger(df, p):\n",
    "    \"\"\"\n",
    "    Fits a VAR(p) model on the input df and performs pairwise Granger Causality tests\n",
    "    \"\"\"\n",
    "    granger_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return granger_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37319af26d829b23bda3f3f379d4dfd0",
     "grade": true,
     "grade_id": "cell-b9358e200e7341eb",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df, p = load_data(), 7\n",
    "stu_ans = test_granger(stu_df, 7)\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q2: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (5, 5), \"Q2: The shape of your pd.DataFrame is not correct. \"\n",
    "assert (stu_ans.index == stu_ans.columns).all(), \"Q2: Your pd.DataFrame should have the same index and column labels. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q2: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_df, stu_ans, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83498ccb722274b12a0cfeb041f6af72",
     "grade": false,
     "grade_id": "cell-b06194f2c905a730",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If we believe in the magic threshold of $0.01$ (or $0.05$) for rejecting null hypotheses, we will obtain the following \"causality matrix\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the causality matrix\n",
    "\n",
    "stu_df, p = load_data(), 7\n",
    "stu_ans = test_granger(stu_df, 7)\n",
    "caul_mtrx = stu_ans.rename(index={item: f\"{item} caused by\" for item in stu_ans.index})\n",
    "caul_mtrx.where(caul_mtrx.isna(), caul_mtrx <= 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6ee2d78e98becb7c9972e49c672ea17",
     "grade": false,
     "grade_id": "cell-089d5174ad4da5df",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What do you think about the causality matrix above? Are there any surprising conclusions? Do you believe in the Granger Causality test we just performed? Why or why not? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
