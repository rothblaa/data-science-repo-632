{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262ee4f1cc793d5cc0302d24cbc64461",
     "grade": false,
     "grade_id": "cell-aa820d6aaf4304db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e6532f169aa91abaedd1300b8defeaa",
     "grade": false,
     "grade_id": "cell-24e63ee011a83003",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 4 Part 1: Sampling a Data Stream (50 pts)\n",
    "\n",
    "In this assignment, we're going to implement two algorithms for sampling a data stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16a67cb7d6c35980c8f29753d98ac687",
     "grade": false,
     "grade_id": "cell-92c51d881ace04f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75ed6ad36fd3a69ba4fd89650ad30f22",
     "grade": false,
     "grade_id": "cell-ffd221b6dbe6c445",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We are interested in understanding the distribution (counts) of emojis in a (potentially unlimited) stream of tweets. However, remember that one of the biggest challenges in mining data streams is that **we have limited storage capacity for the very high volume of incoming data, which may arrive at a very high velocity as well**. So in this week's assignments, **we cannot store or process all tweets at once, but are constrained to deal with only one or a few tweets at a time**. Sampling allows us to maintain a compact representation of the entire data stream and we hope that the distribution of emojis in the sample we collect sheds light on the overall distribution of emojis in the data stream. \n",
    "\n",
    "The `TwitterStream` class defined below is used to simulate a Twitter stream. It works the same way as a `list`, `tuple` or any other `iterable`s that you may have worked with before --- you can loop over it to receive **one tweet at a time**. Each tweet may or may not contain emojis. There's also a helper function `extract_emojis` that helps you extract all emojis from a piece of text. It may be also useful to know that the variable `UNICODE_EMOJI` is a collection of all emojis that are circulating around the world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70b42d4698cc4de05f7858fcd2719e15",
     "grade": false,
     "grade_id": "cell-edbc44e7eed6dd74",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\"\n",
    "    Extract all emojis from a str\n",
    "    \"\"\"\n",
    "    return [ch for ch in text if ch in UNICODE_EMOJI['en']]\n",
    "\n",
    "class TwitterStream:\n",
    "    \"\"\"\n",
    "    Used to simulate a Twitter stream. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "        self.data = open(self.data_file, \"r\")\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.reset()\n",
    "    \n",
    "    def __next__(self):\n",
    "        next_line = self.data.readline()\n",
    "        if next_line:\n",
    "            return json.loads(next_line)[\"text\"]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def __del__(self):\n",
    "        if not self.data.closed:\n",
    "            self.data.close()\n",
    "    \n",
    "    def reset(self):\n",
    "        if not self.data.closed:\n",
    "            self.data.close()\n",
    "        self.data = open(self.data_file, \"r\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e783b44b0eb3d82e2c2d8d9f86a68aac",
     "grade": false,
     "grade_id": "cell-3bae08836640a239",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Understanding how the `TwitterStream` class works is not essential to completing this assignment. You may interact with an instance of the `TwitterStream` class in one of the following two ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_stream = TwitterStream(\"assets/tweets\")  # instantiate a Twitter stream from a data file\n",
    "\n",
    "# use a for-loop to iterate through the stream, just like iterating over a list\n",
    "for index, tweet in enumerate(twitter_stream):\n",
    "    print(index, tweet)\n",
    "    if index >= 3:  # only prints the first 4 tweets\n",
    "        break\n",
    "\n",
    "twitter_stream.reset() # reset the stream so that it begins with the first tweet\n",
    "print()\n",
    "\n",
    "# OR\n",
    "# use a while-loop together with the \"next\" function to retrieve one tweet from the stream at a time\n",
    "index = 0\n",
    "while index < 4: \n",
    "    print(index, next(twitter_stream)) # the built-in \"next\" function retrieves the next item in an iterator\n",
    "    index += 1\n",
    "\n",
    "del twitter_stream, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd8116f08c4c4c03c0846e0e1a79af51",
     "grade": false,
     "grade_id": "cell-dfbedcd9abd69145",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Many sampling algorithms require \"tossing a coin\", that is, a psudo-random generator (PRG). To make sure the autograder can grade your work correctly, we need a special \"history-preserving\" PRG that's defined below. You don't have to worry about its definition but just be aware that it works exactly the same way as the `random` library. An example usage is also provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5009fed8217053efd06d68b786eed2ab",
     "grade": false,
     "grade_id": "cell-c8d26857b6b3ece2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from random import Random\n",
    "from collections import defaultdict\n",
    "\n",
    "class HistPresvRandom:\n",
    "    \"\"\"\n",
    "    History-preserving Random Number Generator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=None):\n",
    "        self.prg = Random(seed)\n",
    "        self.hist = defaultdict(list)\n",
    "    \n",
    "    def random(self): # works exactly like random.random()\n",
    "        num = self.prg.random()\n",
    "        self.hist[\"random\"].append(num)\n",
    "        return num\n",
    "    \n",
    "    def sample(self, population): # works exactly like random.sample(population, 1)[0]\n",
    "        num = self.prg.sample(population, 1)[0]\n",
    "        self.hist[\"sample\"].append(num)\n",
    "        return num\n",
    "\n",
    "hist_presv_random = HistPresvRandom(0)\n",
    "print(f'\"random\" method: {hist_presv_random.random()}')\n",
    "print(f'\"sample\" method: {hist_presv_random.sample(range(10))}')\n",
    "\n",
    "del hist_presv_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6a71cef7f4617a11293c54d37db348c",
     "grade": false,
     "grade_id": "cell-d63bebc6fef0f0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Random Sampling (20 pts)\n",
    "\n",
    "As a warm-up, let's implement the Random Sampling algorithm referred to as \"First Attempt\" in the lecture slides. \n",
    "\n",
    "A partially completed `RandomSampler` class is given to you below. Your job is to complete the following two functions:\n",
    "\n",
    "* `_process_new_item`: it receives a single item and decides whether the item should be added to `self.sample`. It also ensures `self.counts` always has the most updated counts of emojis that are extracted from the tweets in `self.sample`. \n",
    "\n",
    "\n",
    "* `do_sampling`: it receives a stream object and iterates over the stream. During each iteration, it processes a new item as specified by the Random Sampling algorithm. Finally it returns a copy of `self.sample` and `self.counts` for grading at every iteration, which you don't need to worry about. **However, please do make sure you don't inadvertently change the indentation of the `yield` statement.**\n",
    "\n",
    "At the end of every iteration, the autograder checks the content of your `self.sample` and `self.counts`. Below is an example content of both. \n",
    "\n",
    "```\n",
    "self.sample:\n",
    "['Lmaoooooo love you allll', \n",
    "'RT @kaseykreated: BEST CITY IN MISSOURI! Let’s argue 😂😂 https://t.co/p7DWK5OAd5', \n",
    "'Hubble Hooks a One-Arm Galaxy via NASA https://t.co/csOJhfJMpj https://t.co/Aer6ILkskg', \n",
    "'RT @makio_elecom: 先日はアンジュさんをネタにしてしまい、大変申し訳ございませんでした。 https://t.co/9cO6IPV3hB', \n",
    "'#tell حبيبتي شكراًًً💘💘💘']\n",
    "\n",
    "self.counts:\n",
    "defaultdict(<class 'int'>, {'😂': 2, '💘': 3})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d87b3565b9499baa4177d707f26f2d4",
     "grade": false,
     "grade_id": "cell-993d3b939f534f62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class RandomSampler:\n",
    "    \n",
    "    def __init__(self, in_sample_prob, seed=None):\n",
    "        \n",
    "        self.in_sample_prob = in_sample_prob\n",
    "        self.random = HistPresvRandom(seed) # used whenever randomness is needed in your solution\n",
    "        self.sample, self.counts = list(), defaultdict(int) # recommended to use defaultdict, but an ordinary dict works fine too\n",
    "    \n",
    "    def _process_new_item(self, item):\n",
    "        \"\"\"\n",
    "        Applies random sampling to a newly arrived item\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def do_sampling(self, stream):\n",
    "        \"\"\"\n",
    "        Iterates over a stream and performs random sampling\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sample.clear() # clear the existing sample\n",
    "        self.counts.clear() # clear the existing counts\n",
    "        \n",
    "        for item in stream: # iterate over the stream\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            # returns a copy of sample and counts at the end of every iteration for grading - code given\n",
    "            yield self.sample.copy(), self.counts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66742b1fe9d2f68dde08e4426b984c41",
     "grade": true,
     "grade_id": "cell-a7b7858dc829b35f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "twitter_stream = TwitterStream(\"assets/tweets\")\n",
    "\n",
    "# Sanity checks for a trivial case - always includes a new tweet in the sample\n",
    "in_sample_prob, seed = 1.0, 42\n",
    "stu_ans = RandomSampler(in_sample_prob, seed)\n",
    "\n",
    "# Collect all emojis that appeared\n",
    "emojis_appeared = set()\n",
    "for tweet in twitter_stream:\n",
    "    emojis_appeared = emojis_appeared.union(extract_emojis(tweet))\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "stream_size = 0\n",
    "for _ in stu_ans.do_sampling(twitter_stream):\n",
    "    stream_size += 1\n",
    "\n",
    "\n",
    "assert isinstance(stu_ans.sample, list), \"Q1: Your sample should be of type list. \"\n",
    "\n",
    "assert isinstance(stu_ans.counts, dict), \"Q1: Your emoji counts should be of type dict. \"\n",
    "\n",
    "assert len(stu_ans.sample) == stream_size, f\"Q1: When in_sample_prob == {in_sample_prob}, your sample should contain all tweets. \"\n",
    "\n",
    "assert len(stu_ans.counts) == len(emojis_appeared), f\"Q1: The length of your emoji counts ({len(stu_ans.counts)}) differs from the correct answer ({len(emojis_appeared)}). \"\n",
    "\n",
    "assert not (emojis_appeared - set(stu_ans.counts.keys())), f\"Q1: Your emoji counts don't include {emojis_appeared - set(stu_ans.counts.keys())}. \"\n",
    "\n",
    "assert not (set(stu_ans.counts.keys()) - emojis_appeared), f\"Q1: Your emoji counts contain extra emojis: {set(stu_ans.counts.keys()) - emojis_appeared}. \"\n",
    "\n",
    "\n",
    "# Re-define variables for the hidden tests\n",
    "in_sample_prob, seed = 0.1, 42\n",
    "stu_ans = RandomSampler(in_sample_prob, seed)\n",
    "stu_res = stu_ans.do_sampling(twitter_stream)\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del in_sample_prob, seed, twitter_stream, stu_ans, stu_res, emojis_appeared, stream_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34fbe15d75a672982c1087e21e456c1d",
     "grade": false,
     "grade_id": "cell-3257205544428b58",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's see what the emoji distribution is after all tweets are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_prob, seed = 0.1, 42\n",
    "stu_ans = RandomSampler(in_sample_prob, seed)\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "for _ in stu_ans.do_sampling(TwitterStream(\"assets/tweets\")):\n",
    "    pass\n",
    "\n",
    "sorted_counts = {emoji: stu_ans.counts[emoji] for emoji in sorted(stu_ans.counts.keys(), key=stu_ans.counts.get, reverse=True)}\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfccef5882803bfde0dec858b582a7d",
     "grade": false,
     "grade_id": "cell-e2d071f61b433fa0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Visualised in a bar graph, the emoji distribution seems to resemble a [Power Law](https://en.wikipedia.org/wiki/Power_law) distribution. A few emojis are used a lot while the majority of the emojis are rarely used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(range(len(sorted_counts)), sorted_counts.values())\n",
    "ax.set_xlabel(\"Rank\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Emoji Distribution\")\n",
    "\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24453255bee04f7a02d257357306019a",
     "grade": false,
     "grade_id": "cell-2939c5cace465fa0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Reservoir Sampling (30 pts)\n",
    "\n",
    "With reference to the lecture slides, let's now implement the Reservoir Sampling algorithm. \n",
    "\n",
    "A partially completed `ReservoirSampler` class similar in structure to `RandomSampler` is given to you below. Your job is to complete the same two functions:\n",
    "\n",
    "* `_process_new_item`: it receives a single item as well as the index of the item in the stream, and decides whether the item should be added to `self.sample`. **Please always *append* the new item to the end of your `self.sample` instead of replacing an old item with it.** This function also ensures `self.counts` always has the most updated counts of emojis that are extracted from the tweets *currently* in `self.sample`, which means that **the counts of emojis must be adjusted in the event of adding or removing an emoji to/from the sample**. Moreover, an emoji with a count of zero must be completely dropped from `self.counts`. \n",
    "\n",
    "\n",
    "* `do_sampling`: it receives a stream object and iterates over the stream. During each iteration, it processes a new item as specified by the Reservoir Sampling algorithm. Finally it returns a copy of `self.sample` and `self.counts` for grading at every iteration, which you don't need to worry about. **However, please do make sure you don't inadvertently change the indentation of the `yield` statement.**\n",
    "\n",
    "At the end of every iteration, the autograder checks the content of your `self.sample` and `self.counts`. Below is an example content of both. \n",
    "\n",
    "```\n",
    "self.sample:\n",
    "['Recently arrived in Australia - just been out on my evening dog walk and decided to give @petercrouch podcast a listen - wow...what have I been missing - absolutely hilarious! #thatpetercrouchpodcast', \n",
    "'Lmaoooooo love you allll', \n",
    "'Good morning! kita mo nga naman isang panibagong araw para maging malungkot ulit🤧', \n",
    "'Here we go ⚓️']\n",
    "\n",
    "self.counts:\n",
    "defaultdict(<class 'int'>, {'🤧': 1, '⚓': 1})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc463fb9c0afe5704a4ff8f4013bc9a9",
     "grade": false,
     "grade_id": "cell-e896207bcc59798b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class ReservoirSampler:\n",
    "    \n",
    "    def __init__(self, sample_size, seed=None):\n",
    "        \n",
    "        self.sample_size = sample_size\n",
    "        self.random = HistPresvRandom(seed) # used whenever randomness is needed in your solution\n",
    "        self.sample, self.counts = list(), defaultdict(int)\n",
    "    \n",
    "    def _process_new_item(self, item, index):\n",
    "        \"\"\"\n",
    "        Decides whether a new item should be added to the sample and adjusts the counts accordingly\n",
    "        \"\"\"\n",
    "        \n",
    "        #check if random number is less then or equal to sample probability\n",
    "            #create our list of emojis to delete\n",
    "            #remove emojis from sample \n",
    "\n",
    "            #iterate through the emojis from extract_emojis(deleted_items)\n",
    "                #reduce the emoji counts \n",
    "                #if the counts attribute is less than or equal to zero \n",
    "                    #remove emoji from the counts hint use pop or del \n",
    "\n",
    "            #in order to admit the new append the item that has been passed to the method processes new item \n",
    "            #iterate the result of extract_emojis(item)\n",
    "                #update the counter of the iterable \n",
    "                \n",
    "                \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def do_sampling(self, stream):\n",
    "        \"\"\"\n",
    "        Iterates over a stream and performs reservoir sampling\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sample.clear() # clear the existing sample\n",
    "        self.counts.clear() # clear the existing counts\n",
    "        \n",
    "        for index, item in enumerate(stream): # iterate over the stream\n",
    "\n",
    "            #when our sample size is larger then the sample \n",
    "                #we append the item from the stream \n",
    "                #iterate the result of extract_emojis(item)\n",
    "                    #update the counts of each iterable\n",
    "            #otherwise we call the method _process_new_item(item, index)            \n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            # returns a copy of sample and counts at the end of every iteration for grading - code given\n",
    "            yield self.sample.copy(), self.counts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "712642dcb49d900401e04bd86c15b9b1",
     "grade": true,
     "grade_id": "cell-b9358e200e7341eb",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "twitter_stream = TwitterStream(\"assets/tweets\")\n",
    "\n",
    "# Sanity checks for a trivial case - use a large sample size to include all tweets\n",
    "sample_size, seed = 100000, 0\n",
    "stu_ans = ReservoirSampler(sample_size, seed)\n",
    "\n",
    "# Collect all emojis that appeared\n",
    "emojis_appeared = set()\n",
    "for tweet in twitter_stream:\n",
    "    emojis_appeared = emojis_appeared.union(extract_emojis(tweet))\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "stream_size = 0\n",
    "for _ in stu_ans.do_sampling(twitter_stream):\n",
    "    stream_size += 1\n",
    "\n",
    "\n",
    "assert isinstance(stu_ans.sample, list), \"Q2: Your sample should be of type list. \"\n",
    "\n",
    "assert isinstance(stu_ans.counts, dict), \"Q2: Your emoji counts should be of type dict. \"\n",
    "\n",
    "for emoji in stu_ans.counts:\n",
    "    assert stu_ans.counts[emoji] > 0, f\"Q2: {emoji} in your emoji counts has a zero count. \"\n",
    "    \n",
    "assert len(stu_ans.sample) == stream_size, f\"Q2: When sample_size is very large, your sample should contain all tweets. \"\n",
    "\n",
    "assert len(stu_ans.counts) == len(emojis_appeared), f\"Q2: The length of your emoji counts ({len(stu_ans.counts)}) differs from the correct answer ({len(emojis_appeared)}). \"\n",
    "\n",
    "assert not (emojis_appeared - set(stu_ans.counts.keys())), f\"Q2: Your emoji counts don't include {emojis_appeared - set(stu_ans.counts.keys())}. \"\n",
    "\n",
    "assert not (set(stu_ans.counts.keys()) - emojis_appeared), f\"Q2: Your emoji counts contain extra emojis: {set(stu_ans.counts.keys()) - emojis_appeared}. \"\n",
    "\n",
    "\n",
    "# Re-define variables for the hidden tests\n",
    "sample_size, seed = 100, 0\n",
    "stu_ans = ReservoirSampler(sample_size, seed)\n",
    "stu_res = stu_ans.do_sampling(twitter_stream)\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del sample_size, seed, twitter_stream, stu_ans, stu_res, emojis_appeared, stream_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d253e5929be20e48bf8404376b52035",
     "grade": false,
     "grade_id": "cell-7b82d6fd627b1ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's see what the emoji distribution is after all tweets are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size, seed = 100, 0\n",
    "stu_ans = ReservoirSampler(sample_size, seed)\n",
    "\n",
    "# Do sampling. Don't have to collect the results. Just exhaust the stream\n",
    "for _ in stu_ans.do_sampling(TwitterStream(\"assets/tweets\")):\n",
    "    pass\n",
    "\n",
    "sorted_counts = {emoji: stu_ans.counts[emoji] for emoji in sorted(stu_ans.counts.keys(), key=stu_ans.counts.get, reverse=True)}\n",
    "print(sorted_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91ae632c8b46e89e9a520b01d69b4f29",
     "grade": false,
     "grade_id": "cell-993baf112ddd0d7a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Visualised in a bar graph, the emoji distribution seems to somewhat resemble a [Power Law](https://en.wikipedia.org/wiki/Power_law) distribution, too. A few emojis are used a lot while the majority of the emojis are rarely used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(range(len(sorted_counts)), sorted_counts.values())\n",
    "ax.set_xlabel(\"Rank\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Emoji Distribution\")\n",
    "\n",
    "del fig, ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
